{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "64dbd918",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64dbd918",
        "outputId": "c8c19fac-2b35-436d-ce72-a3eea6703143"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv(override=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "42d63342",
      "metadata": {
        "id": "42d63342"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import http.client\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ! pip install -U langchain-groq"
      ],
      "metadata": {
        "id": "082dw2SOrnIM"
      },
      "id": "082dw2SOrnIM",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "ebf221ed",
      "metadata": {
        "id": "ebf221ed"
      },
      "outputs": [],
      "source": [
        "# pick a model\n",
        "from langchain.chat_models import init_chat_model\n",
        "llm = init_chat_model(\"llama-3.3-70b-versatile\", model_provider=\"groq\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "25a34532",
      "metadata": {
        "id": "25a34532"
      },
      "outputs": [],
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def browse(txt: str) -> str:\n",
        "    \"\"\" Call this tool if you want to search the web for current information\"\"\"\n",
        "\n",
        "    conn = http.client.HTTPSConnection(\"google.serper.dev\")\n",
        "    payload = json.dumps({\n",
        "    \"q\": txt,\n",
        "    \"gl\": \"in\"\n",
        "    })\n",
        "    headers = {\n",
        "    'X-API-KEY': os.environ.get(\"SERPER_API_KEY\"),\n",
        "    'Content-Type': 'application/json'\n",
        "    }\n",
        "    conn.request(\"POST\", \"/search\", payload, headers)\n",
        "    res = conn.getresponse()\n",
        "    data = res.read()\n",
        "    #print(data.decode(\"utf-8\"))\n",
        "    data_dict = json.loads(data.decode(\"utf-8\"))\n",
        "    return data_dict['organic'][0]['snippet']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "dc32e225",
      "metadata": {
        "id": "dc32e225"
      },
      "outputs": [],
      "source": [
        "tools_list = [browse]\n",
        "tools_dict = {t.name: t for t in tools_list} # comes in handy at the time of invokation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "5b9e039b",
      "metadata": {
        "id": "5b9e039b"
      },
      "outputs": [],
      "source": [
        "# we create a tool calling Agent by binding a list of tools to the llm\n",
        "llm_with_tools = llm.bind_tools(tools_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "e3cd2ef9",
      "metadata": {
        "id": "e3cd2ef9"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, ToolMessage\n",
        "\n",
        "# This will store all converation\n",
        "chat_history = [\n",
        "    SystemMessage(content=\"You are a chatbot. Depending on the conversation, if user demands current information, you must use the tool 'browse' to get the information. If you do not need current information, you can answer directly. Always try to keep the conversation short and crisp.\")\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "c5ca2988",
      "metadata": {
        "id": "c5ca2988"
      },
      "outputs": [],
      "source": [
        "chat_history=[]\n",
        "llm_with_tools = llm.bind_tools(tools_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "09bb0493",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09bb0493",
        "outputId": "74dcacfe-f4fe-4212-e973-689e37303bf3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '4ywwmyaaz', 'function': {'arguments': '{\"txt\":\"effects of air pollution\"}', 'name': 'browse'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 232, 'total_tokens': 249, 'completion_time': 0.065984086, 'prompt_time': 0.013846616, 'queue_time': 0.19894189, 'total_time': 0.079830702}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_9e1e8f8435', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--4ba9fc1a-4f3e-4173-84a4-0460290c8f6d-0', tool_calls=[{'name': 'browse', 'args': {'txt': 'effects of air pollution'}, 'id': '4ywwmyaaz', 'type': 'tool_call'}], usage_metadata={'input_tokens': 232, 'output_tokens': 17, 'total_tokens': 249})"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "chat_history.append(HumanMessage(content=\"Tell me about the effects of air pollution\"))\n",
        "\n",
        "response = llm_with_tools.invoke(chat_history)\n",
        "response\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "90fe85e8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90fe85e8",
        "outputId": "115e3665-2bef-423e-a9ff-5095c90dc4e5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='Tell me about the effects of air pollution', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '4ywwmyaaz', 'function': {'arguments': '{\"txt\":\"effects of air pollution\"}', 'name': 'browse'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 232, 'total_tokens': 249, 'completion_time': 0.065984086, 'prompt_time': 0.013846616, 'queue_time': 0.19894189, 'total_time': 0.079830702}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_9e1e8f8435', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--4ba9fc1a-4f3e-4173-84a4-0460290c8f6d-0', tool_calls=[{'name': 'browse', 'args': {'txt': 'effects of air pollution'}, 'id': '4ywwmyaaz', 'type': 'tool_call'}], usage_metadata={'input_tokens': 232, 'output_tokens': 17, 'total_tokens': 249})]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "chat_history.append(response)\n",
        "chat_history\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "0a8d9b1c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a8d9b1c",
        "outputId": "ad951fa7-71d6-486c-df45-436421ad4751"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='Tell me about the effects of air pollution', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '4ywwmyaaz', 'function': {'arguments': '{\"txt\":\"effects of air pollution\"}', 'name': 'browse'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 232, 'total_tokens': 249, 'completion_time': 0.065984086, 'prompt_time': 0.013846616, 'queue_time': 0.19894189, 'total_time': 0.079830702}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_9e1e8f8435', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--4ba9fc1a-4f3e-4173-84a4-0460290c8f6d-0', tool_calls=[{'name': 'browse', 'args': {'txt': 'effects of air pollution'}, 'id': '4ywwmyaaz', 'type': 'tool_call'}], usage_metadata={'input_tokens': 232, 'output_tokens': 17, 'total_tokens': 249}),\n",
              " ToolMessage(content='Air pollution harms health, causes acid rain, reduces sunlight, harms plants and animals, and causes respiratory issues, cardiovascular damage, and cancer.', name='browse', tool_call_id='4ywwmyaaz')]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "# Since there was a tool call, execute the tool and append the tool output in the converation\n",
        "\n",
        "chat_history.append(tools_dict[response.tool_calls[0][\"name\"]].invoke(response.tool_calls[0]))\n",
        "chat_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "54341672",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54341672",
        "outputId": "2b6d78fd-a854-43fd-8089-71ee76e45cf5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='20', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 2, 'prompt_tokens': 300, 'total_tokens': 302, 'completion_time': 0.021310654, 'prompt_time': 0.019055902, 'queue_time': 0.191035066, 'total_time': 0.040366556}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_9e1e8f8435', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--2e650272-bd1c-4735-b101-e2a2865b5f97-0', usage_metadata={'input_tokens': 300, 'output_tokens': 2, 'total_tokens': 302})"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "chat_history.append(HumanMessage(content=\"What is 10 plus 10?\"))\n",
        "\n",
        "response = llm_with_tools.invoke(chat_history)\n",
        "response"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Langchain",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.23"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}