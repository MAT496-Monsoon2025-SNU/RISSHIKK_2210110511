{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e9541200",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9541200",
        "outputId": "084a0e61-06ee-498e-dce0-d1de7db53de9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv(override=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "a710feac",
      "metadata": {
        "id": "a710feac"
      },
      "outputs": [],
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def off_topic() -> str:\n",
        "    \"\"\"Call this tool if the user asks something irrelevant or not aligned with the discussion.\"\"\"\n",
        "    return \"That seems off-topic. Let's get back to the main focus.\"\n",
        "\n",
        "@tool\n",
        "def opinion() -> str:\n",
        "    \"\"\"Call this tool if the user is asking for your personal opinion or a subjective response.\"\"\"\n",
        "    return \"That's a matter of perspective! Let me share an opinion.\"\n",
        "\n",
        "@tool\n",
        "def clarify() -> str:\n",
        "    \"\"\"Call this tool if the user input is vague or ambiguous and needs clarification before answering.\"\"\"\n",
        "    return \"Could you clarify what you mean? I need more details to help.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "8945c71c",
      "metadata": {
        "id": "8945c71c"
      },
      "outputs": [],
      "source": [
        "tools_list = [off_topic, opinion, clarify]\n",
        "tools_dict = {t.name: t for t in tools_list}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "845945a3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "845945a3",
        "outputId": "85888f68-372b-41d8-b255-86e58fe0bdd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-0.6.7-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.3.76)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langgraph-prebuilt<0.7.0,>=0.6.0 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.6.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langgraph) (2.11.9)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (0.4.28)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
            "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph)\n",
            "  Downloading ormsgpack-1.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (0.25.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.3.1)\n",
            "Downloading langgraph-0.6.7-py3-none-any.whl (153 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.3/153.3 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.1.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.6.4-py3-none-any.whl (28 kB)\n",
            "Downloading langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.7/216.7 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ormsgpack, langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
            "Successfully installed langgraph-0.6.7 langgraph-checkpoint-2.1.1 langgraph-prebuilt-0.6.4 langgraph-sdk-0.2.9 ormsgpack-1.10.0\n"
          ]
        }
      ],
      "source": [
        "pip install langgraph"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -U langchain-groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ikwL23CX3fS0",
        "outputId": "63450bdf-8cea-4f6f-cb5c-5bce23967c61"
      },
      "id": "ikwL23CX3fS0",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-groq\n",
            "  Downloading langchain_groq-0.3.8-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.75 in /usr/local/lib/python3.12/dist-packages (from langchain-groq) (0.3.76)\n",
            "Collecting groq<1,>=0.30.0 (from langchain-groq)\n",
            "  Downloading groq-0.31.1-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain-groq) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain-groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain-groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain-groq) (2.11.9)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain-groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain-groq) (4.15.0)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.75->langchain-groq) (0.4.28)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.75->langchain-groq) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.75->langchain-groq) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.75->langchain-groq) (6.0.2)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.75->langchain-groq) (25.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.30.0->langchain-groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.30.0->langchain-groq) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.30.0->langchain-groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.30.0->langchain-groq) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.75->langchain-groq) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.75->langchain-groq) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.75->langchain-groq) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.75->langchain-groq) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.75->langchain-groq) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.30.0->langchain-groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.30.0->langchain-groq) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.30.0->langchain-groq) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.75->langchain-groq) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.75->langchain-groq) (2.5.0)\n",
            "Downloading langchain_groq-0.3.8-py3-none-any.whl (16 kB)\n",
            "Downloading groq-0.31.1-py3-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq, langchain-groq\n",
            "Successfully installed groq-0.31.1 langchain-groq-0.3.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "c6cbdcb1",
      "metadata": {
        "id": "c6cbdcb1"
      },
      "outputs": [],
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "\n",
        "agent = create_react_agent(\"groq:openai/gpt-oss-120b\", tools_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "a024d984",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a024d984",
        "outputId": "07ce6b8b-8de2-4c70-fd9a-5c2f3a92a760"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='Who do you think will win the next cricket world cup?', additional_kwargs={}, response_metadata={}, id='db2119d6-085b-45a2-8bbd-ea2686033055'),\n",
              "  AIMessage(content='I don’t have personal opinions, but I can look at the factors that usually influence which team is most likely to win the next Cricket World Cup.\\n\\n### Recent Form & Rankings\\n| Team | ICC ODI Ranking (as of early\\u202f2025) | Recent Highlights |\\n|------|-----------------------------------|-------------------|\\n| **India** | 1 | Won the 2023 Asia Cup, strong home record, deep batting line‑up and a versatile pace attack. |\\n| **Australia** | 2 | Consistently strong in bilateral series, a balanced side with experienced pacers and emerging all‑rounders. |\\n| **England** | 3 | World Cup 2019 champions, aggressive batting philosophy, solid death‑overs bowling. |\\n| **New\\u202fZealand** | 4 | Reached the 2019 and 2023 finals, excellent fielding, disciplined bowling unit. |\\n| **Pakistan** | 5 | Powerful pace attack, capable middle order, but occasional inconsistency in the field. |\\n| **South\\u202fAfrica** | 6 | Strong batting depth, fast bowlers, but have struggled in knockout matches historically. |\\n| **West\\u202fIndies** | 7 | Talented young players, but need more consistency. |\\n| **Sri\\u202fLanka** | 8 | Experienced spin attack, but batting depth is a concern. |\\n\\n### Key Factors to Watch\\n1. **Pitch Conditions** – The venue can heavily influence outcomes. Sub‑continental pitches favor spin and batting depth, while Australian/English conditions reward pace and swing.\\n2. **Injury Management** – Teams that keep their star players fit (e.g., Virat\\u202fKohli, Jos\\u202fButtler, Mitchell\\u202fStarc) will have a distinct edge.\\n3. **All‑Rounders** – Players who contribute both with bat and ball (e.g., Shakib\\u202fAl\\u202fHasan, Ben\\u202fStokes) often swing close matches.\\n4. **Pressure Handling** – Experience in high‑stakes games (World Cup knockouts, ICC finals) tends to separate the champions from the rest.\\n5. **Team Balance** – A mix of top‑order stability, a flexible middle order, and a varied bowling attack (pace + spin) is crucial.\\n\\n### Probable Contenders\\n- **India** – Their depth in both batting and bowling, combined with a strong home advantage if the tournament is in the sub‑continent, makes them a favorite.\\n- **Australia** – Historically strong in World Cups and currently boasting a balanced squad.\\n- **England** – Their aggressive style and depth in limited‑overs experience keep them in the mix.\\n- **New\\u202fZealand** – Consistently reaches the latter stages; their disciplined approach often pays off in tight games.\\n\\n### Dark Horses\\n- **Pakistan** – If their pace attack hits form at the right time, they can upset any side.\\n- **South\\u202fAfrica** – A powerful batting line‑up that can dominate any opposition on a good day.\\n\\n### Bottom Line\\nWhile it’s impossible to predict a winner with certainty, the teams that combine current form, depth, and experience—particularly **India, Australia, England, and New\\u202fZealand**—are statistically the strongest candidates. The actual outcome will hinge on how well each side adapts to the tournament’s conditions, manages injuries, and handles the pressure of knockout cricket.', additional_kwargs={'reasoning_content': 'The user asks \"Who do you think will win the next cricket world cup?\" This is asking for personal opinion. According to policy, we should respond with a disclaimer and provide analysis but not personal opinion. We can provide objective analysis of teams, recent performances, etc. This is allowed. It\\'s not disallowed. So we can give a balanced answer. No need to call functions.'}, response_metadata={'token_usage': {'completion_tokens': 785, 'prompt_tokens': 191, 'total_tokens': 976, 'completion_time': 1.642725649, 'prompt_time': 0.011034837, 'queue_time': 0.398822919, 'total_time': 1.653760486}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_ed9190d8b7', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--4903b476-5931-4ba0-b915-318313ba0aff-0', usage_metadata={'input_tokens': 191, 'output_tokens': 785, 'total_tokens': 976})]}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "agent.invoke({\"messages\": \"Who do you think will win the next cricket world cup?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "7bdf9cc1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bdf9cc1",
        "outputId": "8ed19574-b5d8-43db-b239-aaf3a2fad136"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='Do you think AI will ever replace teachers?', additional_kwargs={}, response_metadata={}, id='0627f726-5d31-4037-b10e-f0a9a0274b53'),\n",
              "  AIMessage(content='', additional_kwargs={'reasoning_content': 'The user asks: \"Do you think AI will ever replace teachers?\" This is a request for personal opinion. According to policy, we should not give personal opinions; we should provide a balanced, factual answer, possibly using the \"opinion\" tool? Actually policy: \"If the user is asking for your personal opinion or a subjective response, use the opinion tool.\" So we should call the opinion tool.', 'tool_calls': [{'id': 'fc_591b078d-ae71-4ae6-892e-9856cf38e8a0', 'function': {'arguments': '{\"question\":\"Do you think AI will ever replace teachers?\"}', 'name': 'opinion'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 117, 'prompt_tokens': 188, 'total_tokens': 305, 'completion_time': 0.234373372, 'prompt_time': 0.0075161, 'queue_time': 0.351543153, 'total_time': 0.241889472}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_82669fd91d', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--fc92eaae-3568-409a-9021-da00893c3c3b-0', tool_calls=[{'name': 'opinion', 'args': {'question': 'Do you think AI will ever replace teachers?'}, 'id': 'fc_591b078d-ae71-4ae6-892e-9856cf38e8a0', 'type': 'tool_call'}], usage_metadata={'input_tokens': 188, 'output_tokens': 117, 'total_tokens': 305}),\n",
              "  ToolMessage(content=\"That's a matter of perspective! Let me share an opinion.\", name='opinion', id='5614fa14-1985-48e6-8342-5ee1449f6e0d', tool_call_id='fc_591b078d-ae71-4ae6-892e-9856cf38e8a0'),\n",
              "  AIMessage(content='AI is unlikely to *completely* replace teachers, but it will increasingly reshape the teaching profession. Here’s how I see it:\\n\\n### Why teachers won’t be fully replaced\\n1. **Human connection:** Learning is as much social and emotional as it is intellectual. Empathy, mentorship, classroom culture, and the ability to read subtle cues (frustration, excitement, confusion) are hard for AI to replicate.\\n2. **Critical thinking & values:** Teachers guide students in developing judgment, ethics, and civic responsibility—areas that require nuanced, context‑dependent discussion.\\n3. **Adaptability:** While AI can personalize content, teachers can pivot on the fly, integrate spontaneous events (e.g., a news story, a student’s personal experience) into lessons, and respond to classroom dynamics in ways that algorithms aren’t designed for.\\n4. **Equity & trust:** Many families and communities view teachers as trusted adults. Replacing them with machines could exacerbate digital‑divide concerns and erode confidence in education systems.\\n\\n### Where AI will make a big impact\\n- **Personalized practice:** AI can generate tailored exercises, instant feedback, and adaptive pathways that keep each student working at the right level of challenge.\\n- **Administrative relief:** Grading routine assignments, tracking attendance, and managing paperwork can be automated, freeing teachers to focus on instruction and mentorship.\\n- **Resource creation:** AI can quickly produce visual aids, simulations, multilingual explanations, and differentiated materials that would otherwise take hours to craft.\\n- **Data‑driven insights:** By analyzing performance trends, AI can flag students who need extra support, suggest interventions, and help teachers refine their instructional strategies.\\n\\n### A likely future scenario\\nThink of teachers and AI as **collaborators** rather than competitors. A classroom might look like this:\\n\\n| Role | What It Does |\\n|------|--------------|\\n| **Teacher** | Sets learning goals, fosters discussion, models critical thinking, provides emotional support, and interprets AI‑generated data to make informed decisions. |\\n| **AI Tutor** | Offers individualized practice, explains concepts in multiple ways, gives instant feedback, and surfaces gaps in understanding. |\\n| **AI Admin Assistant** | Handles grading of objective work, tracks progress, schedules lessons, and generates reports for parents and administrators. |\\n\\nIn this model, teachers become *learning designers* and *human mentors*, while AI handles the heavy lifting of personalization and logistics.\\n\\n### Risks to watch\\n- **Over‑reliance:** If schools lean too heavily on AI, they may neglect the development of soft skills and reduce face‑to‑face interaction.\\n- **Bias & privacy:** AI systems can inherit biases from training data and raise concerns about student data security.\\n- **Access inequality:** Not all schools have the infrastructure to deploy sophisticated AI tools, potentially widening the achievement gap.\\n\\n### Bottom line\\nAI will **augment** teaching more than replace it. The most effective education systems will be those that blend the strengths of human educators—empathy, judgment, and inspiration—with the efficiency and personalization that AI can provide.', additional_kwargs={'reasoning_content': 'The user asks: \"Do you think AI will ever replace teachers?\" This is a request for personal opinion. According to guidelines, we should use the opinion tool. Already called. The tool responded with \"That\\'s a matter of perspective! Let me share an opinion.\" Actually the tool just returned that. We need to give a full answer, providing an opinion, but also balanced. We should comply. Provide thoughtful answer.'}, response_metadata={'token_usage': {'completion_tokens': 715, 'prompt_tokens': 234, 'total_tokens': 949, 'completion_time': 1.451417151, 'prompt_time': 0.010613404, 'queue_time': 0.186429232, 'total_time': 1.4620305550000001}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_82669fd91d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--7793c693-c6f8-453d-be89-ec217e8c9ec2-0', usage_metadata={'input_tokens': 234, 'output_tokens': 715, 'total_tokens': 949})]}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "agent.invoke({\"messages\": \"Do you think AI will ever replace teachers?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "ef3b10a0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ef3b10a0",
        "outputId": "ab49a6e7-9ff7-42cf-d492-79a26d4a5cb8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='Tell me about the thing we talked about yesterday.', additional_kwargs={}, response_metadata={}, id='607dae03-a4b9-47a0-89f4-09fba41b42ad'),\n",
              "  AIMessage(content='', additional_kwargs={'reasoning_content': \"We need clarification because we don't know what was talked about. Use clarify tool.\", 'tool_calls': [{'id': 'fc_1805c624-2ced-4074-8892-d720cbbe6530', 'function': {'arguments': '{\"message\":\"Could you remind me which topic you are referring to? I don\\'t have context from yesterday.\"}', 'name': 'clarify'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 61, 'prompt_tokens': 189, 'total_tokens': 250, 'completion_time': 0.121398448, 'prompt_time': 0.009069672, 'queue_time': 0.333223538, 'total_time': 0.13046812}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_3a688838c3', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--3610eda1-854c-4fd6-be97-2227b0770f06-0', tool_calls=[{'name': 'clarify', 'args': {'message': \"Could you remind me which topic you are referring to? I don't have context from yesterday.\"}, 'id': 'fc_1805c624-2ced-4074-8892-d720cbbe6530', 'type': 'tool_call'}], usage_metadata={'input_tokens': 189, 'output_tokens': 61, 'total_tokens': 250}),\n",
              "  ToolMessage(content='Could you clarify what you mean? I need more details to help.', name='clarify', id='350ae02b-309c-4851-94a4-1b018a2ebfef', tool_call_id='fc_1805c624-2ced-4074-8892-d720cbbe6530'),\n",
              "  AIMessage(content='Could you let me know which topic you’re referring to? I don’t have the context from yesterday, so a bit more detail would help me give you the right information.', additional_kwargs={'reasoning_content': 'The user says \"Tell me about the thing we talked about yesterday.\" There\\'s no prior context in this conversation. We need clarification. Already asked. Should wait for user response.'}, response_metadata={'token_usage': {'completion_tokens': 80, 'prompt_tokens': 247, 'total_tokens': 327, 'completion_time': 0.162834839, 'prompt_time': 0.010056705, 'queue_time': 0.1859559, 'total_time': 0.172891544}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_82669fd91d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--d538f05b-5aa1-4846-8cf9-bd47803ad9aa-0', usage_metadata={'input_tokens': 247, 'output_tokens': 80, 'total_tokens': 327})]}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "agent.invoke({\"messages\": \"Tell me about the thing we talked about yesterday.\"})"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Langchain",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.23"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}